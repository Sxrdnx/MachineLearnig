setwd("/media/sxrdnx/Cosas/MachinLearning/regresionMultiple")
R version
R verssion
R -verssion
r -version
dataset=read.csv("Salary_Data.csv")
setwd("/media/sxrdnx/Cosas/MachinLearning/regresionLinealSimple")
library(caTools)
library(caTools)
dataset=read.csv("Salary_Data.csv")
library(caTools)
set.seed(123)
split=sample.split(dataset$Salary,SplitRatio = 2/3)
training_set=subset(dataset,split==TRUE)
testing_set=subset(dataset,split==FALSE)
#ajustar el modelo Regresion Lineal Simple en el conjunto entrnamiento
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
#Predecir el resultado con el conjunto de test
#'la funcion predic funciona por que las columas
#'del conjunto de ttraining y testing se llaman igual
#'si no fuese asi no funcionaria'#
y_pred=predict(regressor,testing_set)
#visualizacion de datos en conjunto de entrenamiento
#´install.packages("ggplot2")
library(ggplot2)
ggplot() +
geom_point(aes(x=training_set$YearsExperience,y=training_set$Salary),
colour="red") +
geom_line(aes(training_set$YearsExperience,y=predict(regressor,training_set)),color="blue") +
ggtitle("Sueldo vs Años de Experiencia(conjunto de Entrenamiento)") +
xlab("Años de Experiencia") + ylab("Sueldo en ($)")
#visualizacion de datos en conjunto de testing
ggplot() +
geom_point(aes(x=testing_set$YearsExperience,y=testing_set$Salary),
colour="red") +
geom_line(aes(training_set$YearsExperience,y=predict(regressor,training_set)),color="blue") +
ggtitle("Sueldo vs Años de Experiencia(conjunto de Testing)") +
xlab("Años de Experiencia") + ylab("Sueldo en ($)")
setwd("/media/sxrdnx/Cosas/MachinLearning/regresionMultiple")
y_pred = predict(regression,newdata = testing_set)
y_pred = predict(regression,newdata = testing_set)
#----regresion lineal multiple---
#importamos el dataSet
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
#predesimos los resultados con el conjunto de testing
y_pred=predict(regression,newdata=testing_set)
# se construye un modelo optimo con la eliminacion hacia atras
# ----Iniciamos con todas la variables ----
regression= lm(formula=Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data=dataSet)
#dado los valores de significancia de las columnas se elimina la de State(los cuales fueron Adm,State)
regression= lm(formula=Profit ~ R.D.Spend + Marketing.Spend,
data=dataSet)
#Probamos con el nuevo modelo
y_pred = predict(regression,newdata = testing_set)
R. version.
R.version.
R version.
R version
R.version.string
y_pred = predict(regression,newdata = testing_set)
#----regresion lineal multiple---
#importamos el dataSet
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
#predesimos los resultados con el conjunto de testing
y_pred=predict(regression,newdata=testing_set)
# se construye un modelo optimo con la eliminacion hacia atras
# ----Iniciamos con todas la variables ----
regression= lm(formula=Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data=dataSet)
#dado los valores de significancia de las columnas se elimina la de State(los cuales fueron Adm,State)
regression= lm(formula=Profit ~ R.D.Spend + Marketing.Spend,
data=dataSet)
#Probamos con el nuevo modelo
y_pred = predict(regression,newdata = testing_set)
View(dataSet)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)#asi se remplasa (.) para las demas var(~ significa en funcion de..)
regression= lm(formula=Profit ~.,
data=training_set)
load("/media/sxrdnx/Cosas/MachinLearning/regresionMultiple/.RData")
dataSet = dataSet[,c(1,2,3,4,5)]
View(dataSet)
backwardElimination(training_set,SL)
backwardElimination<- function(x,sl) {
nVars = length(x)
for (i in c(1:nVars)){
regressor = lm(formula = Profit ~., data = x)
maxVar = max(coef(summary(regressor))[c(2:nVars),"Pr>|t|"])
if(maxVar > sl){
j = which(coef(summary(regressor))[c(2:nVars),"Pr>|t|"] == maxVar)
x = x[,-j]
}
nVars = nVars -1
}
return(summary(regresor))
}
backwardElimination(training_set,SL)
#importamos el dataSet
dataSet=read.csv("50_Startups.csv")
#manejo de datos categoricos
dataSet$State=factor(dataSet$State,
levels = c("New York","California","Florida"),
labels = c(1,2,3))
#divimos el conjunto de entrenamiento y test
set.seed(123)
split=sample.split(dataSet$Profit,SplitRatio = 0.8)
training_set=subset(dataSet,split==TRUE)
testing_set=subset(dataSet,split==FALSE)
#ajustamos el modelo con el conjunto de entrenamiento
regression= lm(formula=Profit ~.,
data=training_set)
backwardElimination<- function(x,sl) {
nVars = length(x)
for (i in c(1:nVars)){
regressor = lm(formula = Profit ~., data = x)
maxVar = max(coef(summary(regressor))[c(2:nVars),"Pr>|t|"])
if(maxVar > sl){
j = which(coef(summary(regressor))[c(2:nVars),"Pr>|t|"] == maxVar)
x = x[,-j]
}
nVars = nVars -1
}
return(summary(regresor))
}
SL = 0.05
dataSet = dataSet[,c(1,2,3,4,5)]
backwardElimination(training_set,SL)
maxVar = max(coef(summary(regressor))[c(2:nVars),"Pr(>|t|)"])
nVars = length(x)
backwardElimination<- function(x,sl) {
nVars = length(x)
for (i in c(1:nVars)){
regressor = lm(formula = Profit ~., data = x)
#maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
maxVar = max(coef(summary(regressor))[c(2:nVars),"Pr(>|t|)"])
if(maxVar > sl){
#j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
j = which(coef(summary(regressor))[c(2:nVars),"Pr(>|t|)"] == maxVar)
x = x[,-j]
}
nVars = nVars -1
}
return(summary(regresor))
}
SL = 0.05
dataSet = dataSet[,c(1,2,3,4,5)]
View(dataSet)
View(dataSet)
backwardElimination(training_set,SL)
backwardElimination(training_set,SL)
return(summary(regressor))
backwardElimination<- function(x,sl) {
nVars = length(x)
for (i in c(1:nVars)){
regressor = lm(formula = Profit ~., data = x)
#maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
maxVar = max(coef(summary(regressor))[c(2:nVars),"Pr(>|t|)"])
if(maxVar > sl){
#j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
j = which(coef(summary(regressor))[c(2:nVars),"Pr(>|t|)"] == maxVar)
x = x[,-j]
}
nVars = nVars -1
}
return(summary(regressor))
}
backwardElimination(training_set,SL)
